{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checl the class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from readers_preprocess import cut_sequences\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_paths = ['data_bci\\\\row_data\\\\subject1\\\\', 'data_bci\\\\row_data\\\\subject2\\\\','data_bci\\\\row_data\\\\subject3\\\\']\n",
    "keep_columns = ['F4', 'F3', 'AF4', 'AF3', 'class']\n",
    "columns_to_read =  ['Fp1', 'AF3' ,'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', 'CP1', 'CP5',\n",
    "                   'P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8', 'CP6',\n",
    "                   'CP2', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'AF4', 'Fp2', 'Fz', 'Cz','class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(all_paths, columns_to_read, cutoff_beggining, seq_len, cut_step):\n",
    "    map_dict = {2:0, 3:1, 7:2}\n",
    "\n",
    "    columns = ['Fp1', 'AF3' ,'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', 'CP1', 'CP5',\n",
    "               'P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8', 'CP6',\n",
    "               'CP2', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'AF4', 'Fp2', 'Fz', 'Cz','class']\n",
    "    \n",
    "    session_1_mark = '01'\n",
    "    session_2_mark = '02'\n",
    "    session_3_mark = '03'\n",
    "    \n",
    "\n",
    "    data = []\n",
    "    for path in all_paths:\n",
    "        files = os.listdir(path)\n",
    "        \n",
    "        for file in files:\n",
    "            if 'train' not in file:\n",
    "                continue\n",
    "            ascii_grid = np.loadtxt(path+\"\\\\\"+file)\n",
    "            experiment_data = pd.DataFrame(ascii_grid, columns=columns)\n",
    "            experiment_data = experiment_data[columns_to_read]\n",
    "            diffs =(experiment_data['class'] != experiment_data['class'].shift(1))\n",
    "            experiment_data['instance_id'] = diffs.cumsum()\n",
    "            experiment_data['class'] = experiment_data['class'].apply(lambda x : map_dict[x])\n",
    "            experiment_data_seqs, annotations = cut_sequences(experiment_data, columns_to_read[:-1], cutoff_beggining, seq_len, cut_step)\n",
    "            if session_1_mark in file:\n",
    "                session_1_data = experiment_data_seqs\n",
    "                session_1_anots = annotations\n",
    "            elif session_2_mark in file:\n",
    "                session_2_data = experiment_data_seqs\n",
    "                session_2_anots = annotations\n",
    "            elif session_3_mark in file:\n",
    "\n",
    "                session_3_data = experiment_data_seqs\n",
    "                session_3_anots = annotations\n",
    "        data.append(((session_1_data, session_2_data, session_3_data),(session_1_anots, session_2_anots, session_3_anots)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = ['data_bci\\\\row_data\\\\subject1\\\\', 'data_bci\\\\row_data\\\\subject2\\\\','data_bci\\\\row_data\\\\subject3\\\\']\n",
    "keep_columns = ['F4', 'F3', 'AF4', 'AF3', 'class']\n",
    "columns_to_read =  ['Fp1', 'AF3' ,'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', 'CP1', 'CP5',\n",
    "                   'P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8', 'CP6',\n",
    "                   'CP2', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'AF4', 'Fp2', 'Fz', 'Cz','class']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "freq = 512\n",
    "\n",
    "cutoff_beggining = 0\n",
    "seq_len = 0\n",
    "cut_step = 0\n",
    "data = read_data(all_paths, columns_to_read, cutoff_beggining, seq_len, cut_step)\n",
    "seq_len = freq\n",
    "cut_step = freq\n",
    "short_data = read_data(all_paths, columns_to_read, cutoff_beggining, seq_len, cut_step)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sess(X, y, freq=512):\n",
    "    \n",
    "    time_len_dict = {}\n",
    "    num_instances_dict = {}\n",
    "    class_map = {0:'left',1:'right',2:'word'}\n",
    "    for class_num, signal in zip(y, X):\n",
    "        \n",
    "        class_anot = class_map[class_num]\n",
    "        if class_anot not in time_len_dict:\n",
    "            time_len_dict[class_anot] = signal.shape[0]/freq\n",
    "            num_instances_dict[class_anot] = 1\n",
    "        else:\n",
    "            time_len_dict[class_anot] += signal.shape[0]/freq\n",
    "            num_instances_dict[class_anot] += 1\n",
    "\n",
    "    return time_len_dict, num_instances_dict\n",
    " \n",
    "\n",
    "def eval_data(data):\n",
    "    \n",
    "    perssons_time_data = []\n",
    "    perssons_num_data = []\n",
    "    for person_num in range(len(data)):\n",
    "        person_time_dict = {}\n",
    "        person_num_inst_dict = {}\n",
    "        person_data = data[person_num]\n",
    "        for sess_X, sess_y in zip(person_data[0], person_data[1]):\n",
    "            time_len_dict, num_inst_dict = eval_sess(sess_X, sess_y)\n",
    "            num_word = num_inst_dict['word']\n",
    "            num_left = num_inst_dict['left']\n",
    "            num_right = num_inst_dict['right']\n",
    "            len_word = time_len_dict['word']\n",
    "            len_left = time_len_dict['left']\n",
    "            len_right  = time_len_dict['right']\n",
    "            \n",
    "            if 'word' not in person_time_dict:\n",
    "                person_num_inst_dict['word'] = [num_word]\n",
    "                person_num_inst_dict['left'] = [num_left]\n",
    "                person_num_inst_dict['right'] = [num_right]\n",
    "                \n",
    "                person_time_dict['word'] = [len_word]\n",
    "                person_time_dict['left'] = [len_left]\n",
    "                person_time_dict['right'] = [len_right]\n",
    "            else:\n",
    "                person_num_inst_dict['word'].append(num_word)\n",
    "                person_num_inst_dict['left'].append(num_left)\n",
    "                person_num_inst_dict['right'].append(num_right)\n",
    "                \n",
    "                person_time_dict['word'].append(len_word)\n",
    "                person_time_dict['left'].append(len_left)\n",
    "                person_time_dict['right'].append(len_right)\n",
    "\n",
    "        perssons_num_data.append(person_num_inst_dict)\n",
    "        perssons_time_data.append(person_time_dict)\n",
    "    return perssons_num_data,perssons_time_data\n",
    "perssons_num_data, perssons_time_data = eval_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_report(reports, y_labels, tittles):\n",
    "    \n",
    "    def autolabel(rects, xpos='center'):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar in *rects*, displaying its height.\n",
    "\n",
    "        *xpos* indicates which side to place the text w.r.t. the center of\n",
    "        the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "        \"\"\"\n",
    "\n",
    "        ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "        offset = {'center': 0, 'right': 1, 'left': -1}\n",
    "\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() +rect.get_width() / 3, height),\n",
    "                        xytext=(offset[xpos]*3, 3),  # use 3 points offset\n",
    "                        textcoords=\"offset points\",  # in both directions\n",
    "                        ha=ha[xpos], va='bottom')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(2):\n",
    "        ax = axes[i]\n",
    "        report = reports[i]\n",
    "        y_label = y_labels[i]\n",
    "        tittle = tittles[i]\n",
    "    \n",
    "\n",
    "        word = [int(el) for el in report['word']]\n",
    "        left = [int(el) for el in report['left']]\n",
    "        right = [int(el) for el in report['right']]\n",
    "\n",
    "        ind = np.arange(len(word))  # the x locations for the groups\n",
    "        width = 0.5  # the width of the bars\n",
    "\n",
    "        rects1 = ax.bar(ind - width/3, word, width/3,label='word')\n",
    "\n",
    "        rects2 = ax.bar(ind, left, width/3, label='left')\n",
    "\n",
    "        rects3 = ax.bar(ind + width/3, right, width/3, label='right')\n",
    "        # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(tittle)\n",
    "        ax.set_xticks(ind)\n",
    "        ax.set_xticklabels(('session1', 'session2', 'session3'))\n",
    "        ax.legend()\n",
    "\n",
    "        if i==0:\n",
    "            autolabel(rects1, \"left\")\n",
    "            autolabel(rects2, \"center\")\n",
    "            autolabel(rects3, \"right\")\n",
    "\n",
    "        ax.legend(fancybox=True, framealpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1_tittle = 'Volunteer 1'\n",
    "person2_tittle = 'Volunteer 2'\n",
    "person3_tittle = 'Volunteer 3'\n",
    "\n",
    "\n",
    "time_y_label = 'Tottal signal lenght [s]'\n",
    "num_insts_y_label = 'Tottal task repetitions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1_time = perssons_time_data[0]\n",
    "person1_num_insts = perssons_num_data[0]\n",
    "person2_time = perssons_time_data[1]\n",
    "person2_num_insts = perssons_num_data[1]\n",
    "person3_time = perssons_time_data[2]\n",
    "person3_num_insts = perssons_num_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_report([person1_time, person1_num_insts],[ time_y_label, num_insts_y_label], [person1_tittle, person1_tittle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report([person2_time, person2_num_insts],[ time_y_label, num_insts_y_label], [person2_tittle, person2_tittle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report([person3_time, person3_num_insts],[ time_y_label, num_insts_y_label], [person3_tittle, person3_tittle])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
